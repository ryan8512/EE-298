{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 1. Parameters, Imports, and Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "histogram_bins = 1000\n",
    "samples = 1000000\n",
    "training_samples = int(0.9*samples)\n",
    "testing_samples = int(0.1*samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0 #input(\"Please input the mean of the gaussian curve:\")\n",
    "std_dev = 1 #input(\"Please input the stardard deviation of the gaussian curve:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 2. Dataset and Histogramming </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time took: 322.42515110969543\n",
      "Total number of samples check:1000000.0\n"
     ]
    }
   ],
   "source": [
    "raw_dataset = np.random.normal(mean, std_dev,samples)\n",
    "starting_points = np.linspace(np.min(raw_dataset), np.max(raw_dataset), num=histogram_bins, endpoint=False)\n",
    "mid_points = np.zeros(histogram_bins)\n",
    "count = np.zeros(histogram_bins)\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(histogram_bins):\n",
    "    #Edge cases\n",
    "    if i == histogram_bins-1:\n",
    "        maximum = np.max(raw_dataset)\n",
    "    else:\n",
    "        maximum = starting_points[i+1]\n",
    "    \n",
    "    #Get the midpoints\n",
    "    mid_points[i] = starting_points[i]+(starting_points[i] - maximum)/2\n",
    "    \n",
    "    #Sweep through the dataset\n",
    "    for j in raw_dataset:\n",
    "        if ((j >= starting_points[i]) and (j <= maximum)): #Assume no EXACTLY equal number\n",
    "            count[i] = count[i] + 1\n",
    "    \n",
    "end_time = time.time() - start_time\n",
    "print(\"Time took: \"+str(end_time))\n",
    "print(\"Total number of samples check:\"+str(np.sum(count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of testing dataset (histogrammed):(900000,)\n",
      "Size of testing dataset (histogrammed):(100000,)\n"
     ]
    }
   ],
   "source": [
    "def translate_count(count, mid_points):\n",
    "    output = []\n",
    "    for index, occurrence in enumerate(count):\n",
    "        if(occurrence !=0):\n",
    "            for _ in range(int(occurrence)):\n",
    "                output.append(mid_points[index])\n",
    "    output_array = np.array(output)\n",
    "    return output_array\n",
    "\n",
    "dataset = translate_count(count,mid_points)\n",
    "random_dataset = np.random.choice(dataset,samples,replace=False)\n",
    "training_dataset = random_dataset[0:training_samples]\n",
    "testing_dataset = random_dataset[training_samples:(training_samples + testing_samples)]\n",
    "\n",
    "print(\"Size of testing dataset (histogrammed):\"+str(training_dataset.shape))\n",
    "print(\"Size of testing dataset (histogrammed):\"+str(testing_dataset.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 3. Build a 3 layer neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_architecture = [\n",
    "    {\"input_dim\": 1, \"output_dim\": 64, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 64, \"output_dim\": 64, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 64, \"output_dim\": 64, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 64, \"output_dim\": 1, \"activation\": \"relu\"},\n",
    "]\n",
    "\n",
    "def init_layers(nn_architecture, seed = 99):\n",
    "    np.random.seed(seed)\n",
    "    number_of_layers = len(nn_architecture)\n",
    "    params_values = {}\n",
    "\n",
    "    for idx, layer in enumerate(nn_architecture):\n",
    "        layer_idx = idx + 1\n",
    "        layer_input_size = layer[\"input_dim\"]\n",
    "        layer_output_size = layer[\"output_dim\"]\n",
    "        \n",
    "        params_values['W' + str(layer_idx)] = np.random.normal(0,1,(layer_output_size, layer_input_size))\n",
    "        params_values['b' + str(layer_idx)] = np.random.normal(0,1,(layer_output_size, 1))\n",
    "        \n",
    "    return params_values\n",
    "\n",
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def sigmoid_backward(dA, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0;\n",
    "    return dZ;\n",
    "\n",
    "def single_layer_forward_propagation(A_prev, W_curr, b_curr, activation=\"relu\"):\n",
    "    Z_curr = np.dot(W_curr, A_prev) + b_curr\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        activation_func = relu\n",
    "    elif activation == \"sigmoid\":\n",
    "        activation_func = sigmoid\n",
    "    else:\n",
    "        raise Exception('Non-supported activation function')\n",
    "        \n",
    "    return activation_func(Z_curr), Z_curr\n",
    "\n",
    "def full_forward_propagation(X, params_values, nn_architecture):\n",
    "    memory = {}\n",
    "    A_curr = X\n",
    "    \n",
    "    for idx, layer in enumerate(nn_architecture):\n",
    "        layer_idx = idx + 1\n",
    "        A_prev = A_curr\n",
    "        \n",
    "        activ_function_curr = layer[\"activation\"]\n",
    "        W_curr = params_values[\"W\" + str(layer_idx)]\n",
    "        \n",
    "        b_curr = params_values[\"b\" + str(layer_idx)]\n",
    "        A_curr, Z_curr = single_layer_forward_propagation(A_prev, W_curr, b_curr, activ_function_curr)\n",
    "        \n",
    "        memory[\"A\" + str(idx)] = A_prev\n",
    "        memory[\"Z\" + str(layer_idx)] = Z_curr\n",
    "       \n",
    "    return A_curr, memory\n",
    "\n",
    "def get_cost_value(predictions,targets):\n",
    "    # Retrieving number of samples in dataset\n",
    "    samples_num = len(predictions)\n",
    "    \n",
    "    # Summing square differences between predicted and expected values\n",
    "    accumulated_error = 0.0\n",
    "    for prediction, target in zip(predictions, targets):\n",
    "        accumulated_error += (prediction - target)**2\n",
    "        \n",
    "    # Calculating mean and dividing by 2\n",
    "    mae_error = (1.0 / (2*samples_num)) * accumulated_error\n",
    "    \n",
    "    return mae_error\n",
    "\n",
    "def get_accuracy_value(Y_hat, Y):\n",
    "    return 100 - np.mean(np.abs(Y_hat - Y)) * 100\n",
    "\n",
    "def single_layer_backward_propagation(dA_curr, W_curr, b_curr, Z_curr, A_prev, activation=\"relu\"):\n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        backward_activation_func = relu_backward\n",
    "    elif activation == \"sigmoid\":\n",
    "        backward_activation_func = sigmoid_backward\n",
    "    else:\n",
    "        raise Exception('Non-supported activation function')\n",
    "    \n",
    "    dZ_curr = backward_activation_func(dA_curr, Z_curr)\n",
    "    dW_curr = np.dot(dZ_curr, A_prev.T) / m\n",
    "    db_curr = np.sum(dZ_curr, axis=1, keepdims=True) / m\n",
    "    dA_prev = np.dot(W_curr.T, dZ_curr)\n",
    "\n",
    "    return dA_prev, dW_curr, db_curr\n",
    "\n",
    "def full_backward_propagation(Y_hat, Y, memory, params_values, nn_architecture):\n",
    "    grads_values = {}\n",
    "    m = Y.shape[1]\n",
    "    Y = Y.reshape(Y_hat.shape)\n",
    "   \n",
    "    dA_prev = - (np.divide(Y, Y_hat) - np.divide(1 - Y, 1 - Y_hat));\n",
    "    \n",
    "    for layer_idx_prev, layer in reversed(list(enumerate(nn_architecture))):\n",
    "        layer_idx_curr = layer_idx_prev + 1\n",
    "        activ_function_curr = layer[\"activation\"]\n",
    "        \n",
    "        dA_curr = dA_prev\n",
    "        \n",
    "        A_prev = memory[\"A\" + str(layer_idx_prev)]\n",
    "        Z_curr = memory[\"Z\" + str(layer_idx_curr)]\n",
    "        W_curr = params_values[\"W\" + str(layer_idx_curr)]\n",
    "        b_curr = params_values[\"b\" + str(layer_idx_curr)]\n",
    "        \n",
    "        dA_prev, dW_curr, db_curr = single_layer_backward_propagation(\n",
    "            dA_curr, W_curr, b_curr, Z_curr, A_prev, activ_function_curr)\n",
    "        \n",
    "        grads_values[\"dW\" + str(layer_idx_curr)] = dW_curr\n",
    "        grads_values[\"db\" + str(layer_idx_curr)] = db_curr\n",
    "    \n",
    "    return grads_values\n",
    "\n",
    "def update(params_values, grads_values, nn_architecture, learning_rate):\n",
    "    for layer_idx, layer in enumerate(nn_architecture):\n",
    "        params_values[\"W\" + str(layer_idx+1)] -= learning_rate * grads_values[\"dW\" + str(layer_idx+1)]        \n",
    "        params_values[\"b\" + str(layer_idx+1)] -= learning_rate * grads_values[\"db\" + str(layer_idx+1)]\n",
    "\n",
    "    return params_values;\n",
    "\n",
    "def train(X, Y, nn_architecture, epochs, learning_rate):\n",
    "    params_values = init_layers(nn_architecture, 2)\n",
    "    cost_history = []\n",
    "    accuracy_history = []\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        Y_hat, cashe = full_forward_propagation(X, params_values, nn_architecture)\n",
    "        cost = get_cost_value(Y_hat, Y)\n",
    "        cost_history.append(cost)\n",
    "        accuracy = get_accuracy_value(Y_hat, Y)\n",
    "        accuracy_history.append(accuracy)\n",
    "        \n",
    "        grads_values = full_backward_propagation(Y_hat, Y, cashe, params_values, nn_architecture)\n",
    "        params_values = update(params_values, grads_values, nn_architecture, learning_rate)\n",
    "        \n",
    "    return params_values, cost_history, accuracy_history\n",
    "\n",
    "def normal(x,mu,sigma):\n",
    "    return ( 2.*np.pi*sigma**2. )**-.5 * np.exp( -.5 * (x-mu)**2. / sigma**2. )\n",
    "\n",
    "def real_function(inputs,mean,std_dev):\n",
    "    output = []\n",
    "    for i in range(inputs.shape[0]):\n",
    "        gaussian_eq = normal(inputs[i],mean,std_dev)\n",
    "        output.append(sigmoid(gaussian_eq))\n",
    "    \n",
    "    return np.array(output)[np.newaxis,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryab/.local/lib/python3.6/site-packages/ipykernel_launcher.py:108: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'W1': array([[-4.16757847e-01],\n",
       "         [-5.62668272e-02],\n",
       "         [-2.13619610e+00],\n",
       "         [ 1.64027081e+00],\n",
       "         [-1.79343559e+00],\n",
       "         [-8.41747366e-01],\n",
       "         [ 5.02881417e-01],\n",
       "         [-1.24528809e+00],\n",
       "         [-1.05795222e+00],\n",
       "         [-9.09007615e-01],\n",
       "         [ 5.51454045e-01],\n",
       "         [ 2.29220801e+00],\n",
       "         [ 4.15393930e-02],\n",
       "         [-1.11792545e+00],\n",
       "         [ 5.39058321e-01],\n",
       "         [-5.96159700e-01],\n",
       "         [-1.91304965e-02],\n",
       "         [ 1.17500122e+00],\n",
       "         [-7.47870949e-01],\n",
       "         [ 9.02525097e-03],\n",
       "         [-8.78107893e-01],\n",
       "         [-1.56434170e-01],\n",
       "         [ 2.56570452e-01],\n",
       "         [-9.88779049e-01],\n",
       "         [-3.38821966e-01],\n",
       "         [-2.36184031e-01],\n",
       "         [-6.37655012e-01],\n",
       "         [-1.18761229e+00],\n",
       "         [-1.42121723e+00],\n",
       "         [-1.53495196e-01],\n",
       "         [-2.69056960e-01],\n",
       "         [ 2.23136679e+00],\n",
       "         [-2.43476758e+00],\n",
       "         [ 1.12726505e-01],\n",
       "         [ 3.70444537e-01],\n",
       "         [ 1.35963386e+00],\n",
       "         [ 5.01857207e-01],\n",
       "         [-8.44213704e-01],\n",
       "         [ 9.76147160e-06],\n",
       "         [ 5.42352572e-01],\n",
       "         [-3.13508197e-01],\n",
       "         [ 7.71011738e-01],\n",
       "         [-1.86809065e+00],\n",
       "         [ 1.73118467e+00],\n",
       "         [ 1.46767801e+00],\n",
       "         [-3.35677339e-01],\n",
       "         [ 6.11340780e-01],\n",
       "         [ 4.79705919e-02],\n",
       "         [-8.29135289e-01],\n",
       "         [ 8.77102184e-02],\n",
       "         [ 1.00036589e+00],\n",
       "         [-3.81092518e-01],\n",
       "         [-3.75669423e-01],\n",
       "         [-7.44707629e-02],\n",
       "         [ 4.33496330e-01],\n",
       "         [ 1.27837923e+00],\n",
       "         [-6.34679305e-01],\n",
       "         [ 5.08396243e-01],\n",
       "         [ 2.16116006e-01],\n",
       "         [-1.85861239e+00],\n",
       "         [-4.19316482e-01],\n",
       "         [-1.32328898e-01],\n",
       "         [-3.95702397e-02],\n",
       "         [ 3.26003433e-01]]),\n",
       "  'b1': array([[-2.04032305],\n",
       "         [ 0.04625552],\n",
       "         [-0.67767558],\n",
       "         [-1.43943903],\n",
       "         [ 0.52429643],\n",
       "         [ 0.73527958],\n",
       "         [-0.65325027],\n",
       "         [ 0.84245628],\n",
       "         [-0.38151648],\n",
       "         [ 0.06648901],\n",
       "         [-1.09873895],\n",
       "         [ 1.58448706],\n",
       "         [-2.65944946],\n",
       "         [-0.09145262],\n",
       "         [ 0.69511961],\n",
       "         [-2.03346655],\n",
       "         [-0.18946926],\n",
       "         [-0.07721867],\n",
       "         [ 0.82470301],\n",
       "         [ 1.24821292],\n",
       "         [-0.40389227],\n",
       "         [-1.38451867],\n",
       "         [ 1.36723542],\n",
       "         [ 1.21788563],\n",
       "         [-0.46200535],\n",
       "         [ 0.35088849],\n",
       "         [ 0.38186623],\n",
       "         [ 0.56627544],\n",
       "         [ 0.20420798],\n",
       "         [ 1.40669624],\n",
       "         [-1.7379595 ],\n",
       "         [ 1.04082395],\n",
       "         [ 0.38047197],\n",
       "         [-0.21713527],\n",
       "         [ 1.1735315 ],\n",
       "         [-2.34360319],\n",
       "         [ 1.16152149],\n",
       "         [ 0.38607805],\n",
       "         [-1.13313327],\n",
       "         [ 0.43309255],\n",
       "         [-0.30408644],\n",
       "         [ 2.58529487],\n",
       "         [ 1.83533272],\n",
       "         [ 0.44068987],\n",
       "         [-0.71925384],\n",
       "         [-0.58341459],\n",
       "         [-0.32504963],\n",
       "         [-0.56023451],\n",
       "         [-0.90224607],\n",
       "         [-0.59097228],\n",
       "         [-0.27617949],\n",
       "         [-0.51688389],\n",
       "         [-0.69858995],\n",
       "         [-0.92889192],\n",
       "         [ 2.55043824],\n",
       "         [-1.47317325],\n",
       "         [-1.02141473],\n",
       "         [ 0.4323957 ],\n",
       "         [-0.32358007],\n",
       "         [ 0.42382471],\n",
       "         [ 0.79918   ],\n",
       "         [ 1.26261366],\n",
       "         [ 0.75196485],\n",
       "         [-0.99376098]]),\n",
       "  'W2': array([[ 1.10914328, -1.76491773, -0.1144213 , ...,  0.62222041,\n",
       "           0.96078194,  0.75837035],\n",
       "         [-1.13431848, -0.70742089, -1.22142917, ...,  0.15908849,\n",
       "          -2.37440268,  0.05851994],\n",
       "         [ 0.37654591, -0.13547976,  0.3359084 , ..., -0.67736049,\n",
       "           0.32706704, -1.45535944],\n",
       "         ...,\n",
       "         [ 0.65969457,  0.51811001,  0.34021941, ..., -0.34857045,\n",
       "          -0.43419488,  1.75623969],\n",
       "         [ 0.49817489, -0.65590222,  1.14751385, ...,  0.48256503,\n",
       "           1.21465185, -0.81721597],\n",
       "         [-1.00111587, -0.32095036,  0.70091164, ...,  1.37757473,\n",
       "           0.33974511,  0.09961164]]),\n",
       "  'b2': array([[-0.55946852],\n",
       "         [-0.78349636],\n",
       "         [-0.68356181],\n",
       "         [-1.47943264],\n",
       "         [-0.06069349],\n",
       "         [-0.58899512],\n",
       "         [ 0.65392177],\n",
       "         [ 0.12811895],\n",
       "         [ 2.38616774],\n",
       "         [ 0.64875486],\n",
       "         [-1.05984335],\n",
       "         [-3.14030543],\n",
       "         [ 0.61569123],\n",
       "         [-0.10303611],\n",
       "         [ 0.35409744],\n",
       "         [-0.88575747],\n",
       "         [-0.69740975],\n",
       "         [-0.38337638],\n",
       "         [ 1.92853623],\n",
       "         [-1.80619997],\n",
       "         [ 1.16107576],\n",
       "         [-0.99364378],\n",
       "         [ 0.11418171],\n",
       "         [ 0.89539001],\n",
       "         [-1.06783461],\n",
       "         [ 0.80246713],\n",
       "         [ 0.55797111],\n",
       "         [-0.57729095],\n",
       "         [ 1.8903856 ],\n",
       "         [-0.81171523],\n",
       "         [ 1.23384561],\n",
       "         [ 0.07659426],\n",
       "         [-0.59451123],\n",
       "         [-1.07677349],\n",
       "         [-0.96600616],\n",
       "         [ 0.16970426],\n",
       "         [ 1.55601678],\n",
       "         [ 0.29161409],\n",
       "         [-0.51627256],\n",
       "         [ 0.95318176],\n",
       "         [ 0.32546124],\n",
       "         [ 0.22742951],\n",
       "         [-0.52654295],\n",
       "         [-1.07024608],\n",
       "         [ 0.00909287],\n",
       "         [ 1.10352899],\n",
       "         [-0.45121644],\n",
       "         [ 1.15523484],\n",
       "         [-1.3300981 ],\n",
       "         [ 0.18703002],\n",
       "         [ 0.0922958 ],\n",
       "         [ 1.55814727],\n",
       "         [ 1.59423062],\n",
       "         [ 0.60305061],\n",
       "         [ 0.0757071 ],\n",
       "         [ 0.69459406],\n",
       "         [ 0.75875928],\n",
       "         [-0.12465656],\n",
       "         [ 1.20246708],\n",
       "         [-0.15846329],\n",
       "         [-0.47748085],\n",
       "         [ 0.49806349],\n",
       "         [ 0.51460857],\n",
       "         [ 0.70337478]]),\n",
       "  'W3': array([[ 0.88156236,  0.68074783, -0.20637832, ..., -1.04700746,\n",
       "          -1.10004997,  1.9404867 ],\n",
       "         [-1.27037332,  0.02537717, -0.08853701, ...,  1.3939646 ,\n",
       "           0.00749745,  0.430526  ],\n",
       "         [ 2.01860662,  0.51005359, -1.24824517, ..., -0.4869012 ,\n",
       "          -0.34876845, -1.10127081],\n",
       "         ...,\n",
       "         [ 0.26829488, -0.58829124,  1.02620943, ...,  0.49900518,\n",
       "          -0.51315095, -0.4215433 ],\n",
       "         [-1.0983503 , -0.77946652, -0.18378602, ...,  1.92541732,\n",
       "           1.52618593, -0.48498359],\n",
       "         [-0.9647214 , -0.70839283, -0.75056495, ..., -1.48289253,\n",
       "           0.32445568,  2.51914343]]),\n",
       "  'b3': array([[ 0.54347706],\n",
       "         [ 0.01753108],\n",
       "         [-0.40427473],\n",
       "         [ 0.93176438],\n",
       "         [ 0.06771261],\n",
       "         [-0.41765397],\n",
       "         [ 0.39445611],\n",
       "         [ 0.0380763 ],\n",
       "         [ 0.04450158],\n",
       "         [-1.84653182],\n",
       "         [-0.96358719],\n",
       "         [-0.82266459],\n",
       "         [-0.99356929],\n",
       "         [ 0.18794034],\n",
       "         [ 0.49026787],\n",
       "         [-0.81900692],\n",
       "         [-0.72019193],\n",
       "         [-1.45142412],\n",
       "         [ 0.00714234],\n",
       "         [-1.93530633],\n",
       "         [-1.19286559],\n",
       "         [ 1.37827447],\n",
       "         [-0.79773204],\n",
       "         [ 0.06105289],\n",
       "         [-0.79189735],\n",
       "         [ 0.42272543],\n",
       "         [ 0.15073213],\n",
       "         [ 0.36934332],\n",
       "         [ 0.20978324],\n",
       "         [-0.79637198],\n",
       "         [-0.06784015],\n",
       "         [ 1.16591069],\n",
       "         [ 0.34373543],\n",
       "         [-0.18311593],\n",
       "         [-0.06452605],\n",
       "         [ 2.28961496],\n",
       "         [ 0.6695858 ],\n",
       "         [-0.11003034],\n",
       "         [ 0.35615686],\n",
       "         [ 2.87850645],\n",
       "         [ 0.49982328],\n",
       "         [-0.58400115],\n",
       "         [-0.32498428],\n",
       "         [-0.56747014],\n",
       "         [ 0.52782055],\n",
       "         [ 1.84697993],\n",
       "         [ 0.4554681 ],\n",
       "         [-0.01073542],\n",
       "         [ 0.74772555],\n",
       "         [-1.50103182],\n",
       "         [ 0.3259095 ],\n",
       "         [ 0.22727874],\n",
       "         [ 0.48813256],\n",
       "         [ 1.70285333],\n",
       "         [-0.79427599],\n",
       "         [-1.26047869],\n",
       "         [-1.1832148 ],\n",
       "         [-0.56704476],\n",
       "         [ 1.38824461],\n",
       "         [-0.76528058],\n",
       "         [ 0.48774951],\n",
       "         [-1.08026127],\n",
       "         [ 0.61268301],\n",
       "         [ 0.39060258]]),\n",
       "  'W4': array([[ 0.89788425,  2.80365127, -1.96459449, -0.00573167,  1.70899315,\n",
       "           0.49776148, -0.33567496,  0.62481189, -0.39011261, -0.15607811,\n",
       "           0.68484676, -1.50697483, -1.0766827 , -1.06597568, -1.79930162,\n",
       "          -0.29769262, -1.02923944, -1.47013405, -0.32172882, -0.87535745,\n",
       "          -0.62257213, -0.61487872,  1.19002323,  1.35723547,  0.13851101,\n",
       "           1.03005722,  0.56788128, -0.40184403,  1.80590588,  0.46623637,\n",
       "           0.64474808,  0.88673869,  1.22282558,  0.87250607, -0.01261268,\n",
       "          -0.66223437,  1.07118043, -0.50485356,  0.21332833,  0.03635468,\n",
       "          -0.37528376,  0.22226178,  0.46194237,  0.03922073, -0.53547085,\n",
       "           0.85791673, -0.32159997,  0.61431259, -0.89954341, -0.11243054,\n",
       "          -1.37679707,  0.60257014,  0.87777306,  0.48223016, -1.36237963,\n",
       "          -1.35551421,  0.89165903, -0.49907907, -1.33615862,  0.87064221,\n",
       "           0.08638119, -0.15545641,  0.42323673,  0.96433325]]),\n",
       "  'b4': array([[0.13884186]])},\n",
       " [array([0.16565987, 0.15132171, 0.17905266, ..., 0.15412718, 0.15078858,\n",
       "         0.1720662 ]),\n",
       "  array([0.16565987, 0.15132171, 0.17905266, ..., 0.15412718, 0.15078858,\n",
       "         0.1720662 ])],\n",
       " [43.014251792946325, 43.014251792946325])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = real_function(training_dataset,mean,std_dev)\n",
    "train(training_dataset[np.newaxis,:],y,nn_architecture,2,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset[np.newaxis,:].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.718281828459045"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.67523393, -0.61356378],\n",
       "       [ 0.55768168,  0.08155853]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(0,1,(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
